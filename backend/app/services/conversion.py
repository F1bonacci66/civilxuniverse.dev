"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤ (RVT‚ÜíCSV, IFC‚ÜíCSV, RVT‚ÜíIFC)
"""
import asyncio
import os
import tempfile
import shutil
from pathlib import Path
from sqlalchemy.orm import Session
from uuid import UUID
from typing import Optional, List
from datetime import datetime

from app.models.upload import ConversionJob, FileUpload, ConversionLog
from app.services.rvt_to_ifc import RVT2IFCService
from app.services.ifc_to_csv import IFC2CSVService
from app.services.rvt_csv_exporter import RVTCSVExporterService
from app.services.csv_transformer import CSVWideToLongTransformer
from app.services.csv_chunker import CSVChunkerService
from app.services.csv_loader import CSVLoaderService
from app.core.storage import storage_service


class ConversionService:
    """–°–µ—Ä–≤–∏—Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π"""
    
    def __init__(self):
        self.rvt_to_ifc = RVT2IFCService()
        self.ifc_to_csv = IFC2CSVService()
        # –ù–µ —Å–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∑–¥–µ—Å—å, —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        self._rvt_csv_exporter = None
        self.csv_transformer = CSVWideToLongTransformer()
    
    @property
    def rvt_csv_exporter(self):
        """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä RVTCSVExporterService (—Å–æ–∑–¥–∞–µ—Ç—Å—è –ø—Ä–∏ –∫–∞–∂–¥–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö)"""
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø—Ä–∏ –∫–∞–∂–¥–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ —Å–≤–µ–∂–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        return RVTCSVExporterService()
    
    async def start_conversion(
        self,
        db: Session,
        file_upload_id: UUID,
        conversion_type: str,
        user_id: UUID,
        export_settings_id: Optional[UUID] = None,
    ) -> ConversionJob:
        """
        –ù–∞—á–∞—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é —Ñ–∞–π–ª–∞
        
        Args:
            db: –°–µ—Å—Å–∏—è –ë–î
            file_upload_id: ID –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            conversion_type: –¢–∏–ø –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (RVT_TO_IFC, IFC_TO_CSV, RVT_TO_CSV)
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            export_settings_id: ID –Ω–∞—Å—Ç—Ä–æ–µ–∫ —ç–∫—Å–ø–æ—Ä—Ç–∞
            
        Returns:
            –°–æ–∑–¥–∞–Ω–Ω–∞—è –∑–∞–¥–∞—á–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        """
        # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
        file_upload = db.query(FileUpload).filter(FileUpload.id == file_upload_id).first()
        if not file_upload:
            raise ValueError("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –î–ª—è RVT_TO_CSV –ø—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–Ω—è—Ç –ª–∏ Windows —Å–µ—Ä–≤–µ—Ä
        should_queue = False
        if conversion_type == "RVT_TO_CSV":
            try:
                exporter = self.rvt_csv_exporter
                if exporter.use_remote and exporter.remote_service:
                    is_busy = await exporter.remote_service.is_busy()
                    if is_busy:
                        should_queue = True
                        self._log_conversion(
                            db,
                            ConversionJob(file_upload_id=file_upload_id, user_id=user_id, conversion_type=conversion_type),
                            "Windows —Å–µ—Ä–≤–µ—Ä –∑–∞–Ω—è—Ç, –∑–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å",
                            level="INFO",
                        )
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å, —Å—á–∏—Ç–∞–µ–º —Å–µ—Ä–≤–µ—Ä –∑–∞–Ω—è—Ç—ã–º (–±–µ–∑–æ–ø–∞—Å–Ω–µ–µ)
                should_queue = True
                print(f"‚ö†Ô∏è [ConversionService] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å Windows —Å–µ—Ä–≤–µ—Ä–∞: {e}, —Å—Ç–∞–≤–∏–º –≤ –æ—á–µ—Ä–µ–¥—å")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        initial_status = "queued" if should_queue else "pending"
        job = ConversionJob(
            file_upload_id=file_upload_id,
            user_id=user_id,
            conversion_type=conversion_type,
            status=initial_status,
            progress=0,
            input_file_id=file_upload_id,
            export_settings_id=export_settings_id,
        )
        db.add(job)
        db.commit()
        db.refresh(job)
        
        # –ï—Å–ª–∏ –∑–∞–¥–∞—á–∞ –≤ –æ—á–µ—Ä–µ–¥–∏, –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–∑—É
        if should_queue:
            self._log_conversion(
                db,
                job,
                f"–ó–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å. –¢–µ–∫—É—â–∏–π —Å—Ç–∞—Ç—É—Å Windows —Å–µ—Ä–≤–µ—Ä–∞: –∑–∞–Ω—è—Ç",
                level="INFO",
            )
            return job
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ
        if conversion_type == "RVT_TO_CSV":
            await self._convert_rvt_to_csv(db, job, file_upload, export_settings_id)
        elif conversion_type == "RVT_TO_IFC":
            await self._convert_rvt_to_ifc(db, job, file_upload, export_settings_id)
        elif conversion_type == "IFC_TO_CSV":
            await self._convert_ifc_to_csv(db, job, file_upload)
        
        return job
    
    def _log_conversion(
        self,
        db: Session,
        job: ConversionJob,
        message: str,
        level: str = "INFO",
        metadata: Optional[dict] = None,
    ):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª–æ–≥ –æ–ø–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        try:
            log = ConversionLog(
                conversion_job_id=job.id,
                log_level=level,
                message=message,
                log_metadata=metadata,
            )
            db.add(log)
            db.commit()
        except Exception:
            db.rollback()
            raise
    
    def _update_job_progress(
        self,
        db: Session,
        job: ConversionJob,
        progress: Optional[int] = None,
        status: Optional[str] = None,
    ):
        """–û–±–Ω–æ–≤–∏—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –∏ —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏"""
        changed = False
        if progress is not None and job.progress != progress:
            job.progress = progress
            changed = True
        if status and job.status != status:
            job.status = status
            changed = True
        if changed:
            db.commit()
    
    async def _convert_rvt_to_csv(
        self,
        db: Session,
        job: ConversionJob,
        file_upload: FileUpload,
        export_settings_id: Optional[UUID] = None,
    ):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å RVT –Ω–∞–ø—Ä—è–º—É—é –≤ CSV —Å –ø–æ–º–æ—â—å—é RvtExporterCfg1.exe."""
        tmp_dir = None
        try:
            job.status = "processing"
            job.progress = 5
            job.started_at = datetime.utcnow()
            db.commit()
            self._log_conversion(db, job, "–ó–∞–ø—É—â–µ–Ω–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è RVT‚ÜíCSV (RvtExporterCfg1.exe)")

            if export_settings_id:
                self._log_conversion(
                    db,
                    job,
                    "–ü–µ—Ä–µ–¥–∞–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞, –Ω–æ –ø—Ä—è–º–æ–π RVT‚ÜíCSV –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é",
                    metadata={"exportSettingsId": str(export_settings_id)},
                )

            tmp_dir = tempfile.mkdtemp()
            local_rvt_name = Path(file_upload.original_filename or f"{job.id}.rvt").name
            local_rvt_path = os.path.join(tmp_dir, local_rvt_name)

            storage_path = file_upload.storage_path
            if storage_path.startswith("local://"):
                storage_path = storage_path[8:]

            if storage_service._use_local_storage:
                source_path = os.path.join(storage_service._local_storage_path, storage_path)
                if not os.path.exists(source_path):
                    raise FileNotFoundError(f"RVT —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: {source_path}")
                shutil.copy2(source_path, local_rvt_path)
            else:
                storage_service.download_file(storage_path, local_rvt_path)

            job.progress = 20
            db.commit()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä—É
            file_size = os.path.getsize(local_rvt_path) if os.path.exists(local_rvt_path) else 0
            self._log_conversion(
                db,
                job,
                "RVT —Ñ–∞–π–ª –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞",
                metadata={
                    "localPath": local_rvt_path,
                    "fileSize": file_size,
                    "fileSizeMB": round(file_size / 1024 / 1024, 2) if file_size > 0 else 0,
                    "exists": os.path.exists(local_rvt_path),
                    "readable": os.access(local_rvt_path, os.R_OK) if os.path.exists(local_rvt_path) else False,
                },
            )

            # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞
            self._log_conversion(
                db,
                job,
                "–ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä RvtExporterCfg1.exe",
                metadata={
                    "rvtFilePath": local_rvt_path,
                    "outputDir": tmp_dir,
                    "rvtFileSize": os.path.getsize(local_rvt_path) if os.path.exists(local_rvt_path) else 0,
                },
            )
            
            try:
                print(f"üîµ [ConversionService] –í—ã–∑—ã–≤–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:")
                print(f"   rvt_file_path: {local_rvt_path}")
                print(f"   output_dir: {tmp_dir}")
                # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞
                def log_from_exporter(message: str, level: str = "INFO", metadata: dict = None):
                    self._log_conversion(db, job, message, level=level, metadata=metadata)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ None –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π
                # –ï—Å–ª–∏ None, –ø–µ—Ä–µ–¥–∞–µ–º None (–Ω–µ —Å—Ç—Ä–æ–∫—É "None"), —á—Ç–æ–±—ã –æ–Ω–∏ –Ω–µ –±—ã–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ –∑–∞–ø—Ä–æ—Å
                project_id = str(file_upload.project_id) if file_upload.project_id is not None else None
                version_id = str(file_upload.version_id) if file_upload.version_id is not None else None
                user_id = str(file_upload.user_id) if file_upload.user_id is not None else None
                file_upload_id = str(file_upload.id) if file_upload.id is not None else None
                
                exporter_result = await asyncio.to_thread(
                    self.rvt_csv_exporter.convert,
                    rvt_file_path=local_rvt_path,
                    output_dir=tmp_dir,
                    log_callback=log_from_exporter,
                    project_id=project_id,
                    version_id=version_id,
                    user_id=user_id,
                    file_upload_id=file_upload_id,
                    model_name=Path(file_upload.original_filename or "").stem or Path(local_rvt_path).stem,
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ exporter_result –Ω–µ None
                if exporter_result is None:
                    raise Exception("–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä –≤–µ—Ä–Ω—É–ª None –≤–º–µ—Å—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")
                
                print(f"‚úÖ [ConversionService] –≠–∫—Å–ø–æ—Ä—Ç—ë—Ä –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
                print(f"   success: {exporter_result.get('success')}")
                print(f"   returncode: {exporter_result.get('returncode')}")
                print(f"   error: {exporter_result.get('error')}")
                print(f"   stdout length: {len(exporter_result.get('stdout', ''))}")
                print(f"   stderr length: {len(exporter_result.get('stderr', ''))}")
            except Exception as e:
                import traceback
                error_trace = traceback.format_exc()
                print(f"‚ùå [ConversionService] –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞: {e}")
                print(f"   Traceback: {error_trace}")
                raise
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞ –∏ stdout/stderr –ü–ï–†–ï–î –ø—Ä–æ–≤–µ—Ä–∫–æ–π success
            # –≠—Ç–æ –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –ª–æ–≥–∏ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∏—Å—å –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
            stdout = exporter_result.get("stdout", "")
            stderr = exporter_result.get("stderr", "")
            command = exporter_result.get("command", "")
            returncode = exporter_result.get("returncode", 0)
            success = exporter_result.get("success", False)
            
            self._log_conversion(
                db,
                job,
                "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É",
                metadata={
                    "success": success,
                    "returncode": returncode,
                    "hasOutputPath": bool(exporter_result.get("output_path")),
                    "outputPath": exporter_result.get("output_path"),
                    "error": exporter_result.get("error"),
                    "stdoutLength": len(stdout),
                    "stderrLength": len(stderr),
                    "command": command[:500] if command else "",  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∫–æ–º–∞–Ω–¥—ã
                },
            )
            
            # –õ–æ–≥–∏—Ä—É–µ–º stdout/stderr —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (–¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ)
            if stdout:
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π stdout (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–ª–∏–Ω–Ω—ã–º, –Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)
                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏, –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π
                max_length = 5000
                if len(stdout) > max_length:
                    # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ —á–∞—Å—Ç–∏
                    stdout_start = stdout[:max_length]
                    stdout_end = stdout[-max_length:]
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stdout (–Ω–∞—á–∞–ª–æ)",
                        metadata={
                            "stdout": stdout_start,
                            "fullLength": len(stdout),
                            "part": "start",
                        },
                    )
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stdout (–∫–æ–Ω–µ—Ü)",
                        metadata={
                            "stdout": stdout_end,
                            "fullLength": len(stdout),
                            "part": "end",
                        },
                    )
                else:
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stdout",
                        metadata={
                            "stdout": stdout,
                            "fullLength": len(stdout),
                        },
                    )
            if stderr:
                # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π stderr
                max_length = 5000
                if len(stderr) > max_length:
                    stderr_start = stderr[:max_length]
                    stderr_end = stderr[-max_length:]
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stderr (–Ω–∞—á–∞–ª–æ)",
                        metadata={
                            "stderr": stderr_start,
                            "fullLength": len(stderr),
                            "part": "start",
                        },
                    )
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stderr (–∫–æ–Ω–µ—Ü)",
                        metadata={
                            "stderr": stderr_end,
                            "fullLength": len(stderr),
                            "part": "end",
                        },
                    )
                else:
                    self._log_conversion(
                        db,
                        job,
                        "–≠–∫—Å–ø–æ—Ä—Ç—ë—Ä stderr",
                        metadata={
                            "stderr": stderr,
                            "fullLength": len(stderr),
                        },
                    )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º success –ü–û–°–õ–ï –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è stdout/stderr
            if not success:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —É—Å–ø–µ—à–Ω–æ - –Ω–µ –∫–æ–ø–∏—Ä—É–µ–º CSV –∏ –Ω–µ —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
                # –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –æ—Å—Ç–∞–Ω–µ—Ç—Å—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                raise Exception(exporter_result.get("error", "–≠–∫—Å–ø–æ—Ä—Ç RVT‚ÜíCSV –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π"))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ CSV –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ
            processed_on_windows = exporter_result.get("processed_on_windows", False)
            
            # –ï—Å–ª–∏ CSV –æ–±—Ä–∞–±–æ—Ç–∞–Ω –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É stdout
            if not processed_on_windows:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å "Successfully exported" –≤ stdout
                # –ù–û: –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ stdout –±—É–¥–µ—Ç –ø—É—Å—Ç—ã–º, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                stdout = exporter_result.get("stdout", "")
                is_remote_conversion = not stdout and success and exporter_result.get("output_path")
                
                if not is_remote_conversion:
                    # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "Successfully exported" –≤ stdout
                    has_success = "successfully exported" in stdout.lower() if stdout else False
                    if not has_success:
                        # –ù–µ—Ç "Successfully exported" - —ç—Ç–æ –æ—à–∏–±–∫–∞, –¥–∞–∂–µ –µ—Å–ª–∏ success=True
                        raise Exception("–≠–∫—Å–ø–æ—Ä—Ç –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ: –Ω–µ—Ç 'Successfully exported' –≤ –ª–æ–≥–∞—Ö")
            
            if processed_on_windows:
                # CSV —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ë–î –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ
                # –ù–µ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å CSV –Ω–∞ Linux —Å–µ—Ä–≤–µ—Ä–µ
                rows_loaded = exporter_result.get("rows_loaded", 0)
                total_parts = exporter_result.get("total_parts", 0)
                
                self._log_conversion(
                    db,
                    job,
                    "CSV –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ –∑–∞–≥—Ä—É–∂–µ–Ω –≤ –ë–î –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ",
                    metadata={
                        "rows_loaded": rows_loaded,
                        "total_parts": total_parts,
                    },
                )
                
                # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á—É
                job.status = "completed"
                job.progress = 100
                job.completed_at = datetime.utcnow()
                if job.started_at:
                    started = job.started_at.replace(tzinfo=None) if job.started_at.tzinfo else job.started_at
                    completed = job.completed_at.replace(tzinfo=None) if job.completed_at.tzinfo else job.completed_at
                    job.duration_seconds = int((completed - started).total_seconds())
                db.commit()
                self._log_conversion(
                    db,
                    job,
                    "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
                    metadata={"rows_loaded": rows_loaded, "total_parts": total_parts},
                )
                return  # –ó–∞–≤–µ—Ä—à–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, CSV —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω
            
            # CSV –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞ Linux —Å–µ—Ä–≤–µ—Ä–µ (—Å—Ç–∞—Ä–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
            # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É (—ç—Ç–æ –∏—Å—Ö–æ–¥–Ω—ã–π –ø—É—Ç—å, –Ω–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
            raw_csv_source_path = exporter_result.get("output_path")
            
            # –ö–æ–ø–∏—Ä—É–µ–º CSV –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –≤ tmp_dir —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            if not raw_csv_source_path or not os.path.exists(raw_csv_source_path):
                raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞: {raw_csv_source_path}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ tmp_dir (–¥–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏)
            raw_csv_source_path_normalized = os.path.normpath(raw_csv_source_path)
            tmp_dir_normalized = os.path.normpath(tmp_dir)
            
            if raw_csv_source_path_normalized.startswith(tmp_dir_normalized):
                # –§–∞–π–ª —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ tmp_dir (—É–¥–∞–ª–µ–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è), –Ω–µ –∫–æ–ø–∏—Ä—É–µ–º
                raw_csv_path = raw_csv_source_path
                self._log_conversion(
                    db,
                    job,
                    "CSV —Ñ–∞–π–ª —É–∂–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—É–¥–∞–ª–µ–Ω–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è)",
                    metadata={
                        "csvPath": raw_csv_path,
                        "tmpDir": tmp_dir,
                        "sourceExists": os.path.exists(raw_csv_source_path),
                    },
                )
            else:
                # –§–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (–ª–æ–∫–∞–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è), –∫–æ–ø–∏—Ä—É–µ–º
                csv_filename = Path(raw_csv_source_path).name
                raw_csv_path = os.path.join(tmp_dir, csv_filename)
                
                self._log_conversion(
                    db,
                    job,
                    "–ö–æ–ø–∏—Ä—É–µ–º CSV —Ñ–∞–π–ª –∏–∑ –∏—Å—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏",
                    metadata={
                        "sourcePath": raw_csv_source_path,
                        "destinationPath": raw_csv_path,
                        "sourceExists": os.path.exists(raw_csv_source_path),
                    },
                )
                
                shutil.copy2(raw_csv_source_path, raw_csv_path)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª—Å—è
            if not os.path.exists(raw_csv_path):
                raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: {raw_csv_path}")
            
            self._log_conversion(
                db,
                job,
                "CSV —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω",
                metadata={
                    "csvPath": raw_csv_path,
                    "csvSize": os.path.getsize(raw_csv_path),
                },
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä CSV —Ñ–∞–π–ª–∞
            csv_size = 0
            csv_lines = 0
            if raw_csv_path and os.path.exists(raw_csv_path):
                csv_size = os.path.getsize(raw_csv_path)
                try:
                    with open(raw_csv_path, 'r', encoding='utf-8-sig') as f:
                        csv_lines = sum(1 for _ in f)
                except Exception:
                    pass
            
            job.progress = 45
            db.commit()
            self._log_conversion(
                db,
                job,
                "RvtExporterCfg1.exe –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É",
                metadata={
                    "csvPath": raw_csv_path,
                    "csvSize": csv_size,
                    "csvLines": csv_lines,
                },
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π CSV —Ñ–∞–π–ª –æ—Ç —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            if raw_csv_path and os.path.exists(raw_csv_path):
                try:
                    from app.utils.storage import build_storage_path, extract_names_from_storage_path
                    
                    model_stem = Path(file_upload.original_filename or "").stem or Path(local_rvt_path).stem
                    raw_csv_filename = f"{model_stem}_raw.csv"
                    
                    storage_path = file_upload.storage_path
                    project_name, version_name = extract_names_from_storage_path(storage_path)
                    
                    self._log_conversion(
                        db,
                        job,
                        "–ù–∞—á–∏–Ω–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞",
                        metadata={
                            "rawCsvSourcePath": raw_csv_path,
                            "rawCsvFilename": raw_csv_filename,
                            "projectName": project_name,
                            "versionName": version_name,
                            "csvSize": csv_size,
                        },
                    )
                    
                    raw_csv_object_name = build_storage_path(
                        project_id=file_upload.project_id,
                        version_id=file_upload.version_id,
                        filename=raw_csv_filename,
                        project_name=project_name,
                        version_name=version_name,
                        use_original_filename=True,
                    )
                    
                    self._log_conversion(
                        db,
                        job,
                        "–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ CSV —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω",
                        metadata={
                            "rawCsvObjectName": raw_csv_object_name,
                        },
                    )
                    
                    storage_path_result = storage_service.upload_file(
                        raw_csv_path,
                        raw_csv_object_name,
                        content_type="text/csv",
                    )
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª—Å—è
                    if storage_service._use_local_storage:
                        # –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–∑–∏—á–µ—Å–∫–æ–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                        local_storage_path = storage_service._local_storage_path
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∏–∑ storage_path_result (–º–æ–∂–µ—Ç –±—ã—Ç—å local://path –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ path)
                        object_path = storage_path_result
                        if object_path.startswith("local://"):
                            object_path = object_path[8:]
                        local_file_path = os.path.join(local_storage_path, object_path)
                        
                        if not os.path.exists(local_file_path):
                            raise FileNotFoundError(
                                f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {local_file_path} "
                                f"(storage_path_result: {storage_path_result}, object_path: {object_path})"
                            )
                        actual_size = os.path.getsize(local_file_path)
                        if actual_size != csv_size:
                            self._log_conversion(
                                db,
                                job,
                                "–í–ù–ò–ú–ê–ù–ò–ï: –†–∞–∑–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º",
                                level="WARNING",
                                metadata={
                                    "expectedSize": csv_size,
                                    "actualSize": actual_size,
                                    "filePath": local_file_path,
                                },
                            )
                        else:
                            self._log_conversion(
                                db,
                                job,
                                "–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω",
                                metadata={
                                    "filePath": local_file_path,
                                    "fileSize": actual_size,
                                },
                            )
                    
                    self._log_conversion(
                        db,
                        job,
                        "–ò—Å—Ö–æ–¥–Ω—ã–π CSV —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
                        metadata={
                            "storagePath": storage_path_result,
                            "objectName": raw_csv_object_name,
                        },
                    )
                    
                    raw_csv_file_upload = FileUpload(
                        user_id=file_upload.user_id,
                        project_id=file_upload.project_id,
                        version_id=file_upload.version_id,
                        original_filename=raw_csv_filename,
                        file_type="CSV",
                        file_size=csv_size,
                        mime_type="text/csv",
                        storage_path=storage_path_result,
                        storage_bucket=storage_service.bucket or "local",
                        upload_status="completed",
                    )
                    db.add(raw_csv_file_upload)
                    db.commit()
                    db.refresh(raw_csv_file_upload)
                    
                    self._log_conversion(
                        db,
                        job,
                        "–ò—Å—Ö–æ–¥–Ω—ã–π CSV —Ñ–∞–π–ª –æ—Ç —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω",
                        metadata={
                            "rawCsvFileId": str(raw_csv_file_upload.id),
                            "rawCsvPath": storage_path_result,
                            "rawCsvSize": csv_size,
                            "rawCsvObjectName": raw_csv_object_name,
                        },
                    )
                except Exception as save_error:
                    # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                    import traceback
                    error_trace = traceback.format_exc()
                    self._log_conversion(
                        db,
                        job,
                        f"–û–®–ò–ë–ö–ê –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞: {str(save_error)}",
                        level="ERROR",
                        metadata={
                            "error": str(save_error),
                            "traceback": error_trace,
                            "rawCsvPath": raw_csv_path if raw_csv_path else None,
                        },
                    )
                    # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º CSV
            else:
                self._log_conversion(
                    db,
                    job,
                    "–ò—Å—Ö–æ–¥–Ω—ã–π CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è",
                    level="WARNING",
                    metadata={
                        "rawCsvPath": raw_csv_path,
                        "exists": os.path.exists(raw_csv_path) if raw_csv_path else False,
                    },
                )

            model_stem = Path(file_upload.original_filename or "").stem or Path(local_rvt_path).stem
            normalized_csv_name = f"{model_stem}_normalized.csv"
            normalized_csv_path = os.path.join(tmp_dir, normalized_csv_name)

            transform_stats = self.csv_transformer.transform(
                source_path=raw_csv_path,
                destination_path=normalized_csv_path,
                model_name=model_stem,
            )

            job.progress = 55
            db.commit()
            self._log_conversion(
                db,
                job,
                "CSV –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –ë–î",
                metadata=transform_stats,
            )

            await self._process_csv_output(
                db=db,
                job=job,
                source_file_upload=file_upload,
                csv_file_path=normalized_csv_path,
                tmp_dir=tmp_dir,
            )
        except Exception as e:
            job.status = "failed"
            job.error_message = str(e)
            job.completed_at = datetime.utcnow()
            if job.started_at:
                started = job.started_at.replace(tzinfo=None) if job.started_at.tzinfo else job.started_at
                completed = job.completed_at.replace(tzinfo=None) if job.completed_at.tzinfo else job.completed_at
                job.duration_seconds = int((completed - started).total_seconds())
            db.commit()
            self._log_conversion(db, job, f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ RVT‚ÜíCSV: {e}", level="ERROR")
            # –í–ê–ñ–ù–û: –ü—Ä–∏ –æ—à–∏–±–∫–µ –ù–ï —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å—Ä–∞–∑—É
            # –û–Ω–∞ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤–∞–∂–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ (CSV, RVT, –ª–æ–≥–∏)
            # –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–∞ –ø–æ–∑–∂–µ —Å–∏—Å—Ç–µ–º–æ–π –æ—á–∏—Å—Ç–∫–∏ –∏–ª–∏ –≤—Ä—É—á–Ω—É—é
            self._log_conversion(
                db,
                job,
                "–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏",
                metadata={
                    "tmpDir": tmp_dir,
                    "exists": os.path.exists(tmp_dir) if tmp_dir else False,
                },
            )
            raise
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¢–û–õ–¨–ö–û –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            # –ï—Å–ª–∏ –±—ã–ª–∞ –æ—à–∏–±–∫–∞, –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–∂–µ –Ω–µ –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–∞ (–æ—Å—Ç–∞–ª–∞—Å—å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —É—Å–ø–µ—à–Ω–æ (job.status == "completed")
            if tmp_dir and os.path.exists(tmp_dir):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ - —É–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
                db.refresh(job)
                if job.status == "completed":
                    try:
                        shutil.rmtree(tmp_dir, ignore_errors=True)
                        self._log_conversion(
                            db,
                            job,
                            "–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —É–¥–∞–ª–µ–Ω–∞ –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è",
                            metadata={"tmpDir": tmp_dir},
                        )
                    except Exception as cleanup_error:
                        self._log_conversion(
                            db,
                            job,
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {cleanup_error}",
                            level="WARNING",
                            metadata={"tmpDir": tmp_dir},
                        )
                else:
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —É—Å–ø–µ—à–Ω–æ - –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –æ—Å—Ç–∞–µ—Ç—Å—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                    self._log_conversion(
                        db,
                        job,
                        "–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (–∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —É—Å–ø–µ—à–Ω–æ)",
                        metadata={
                            "tmpDir": tmp_dir,
                            "jobStatus": job.status,
                        },
                    )
    
    async def _convert_rvt_to_ifc(
        self,
        db: Session,
        job: ConversionJob,
        file_upload: FileUpload,
        export_settings_id: Optional[UUID],
    ):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å RVT –≤ IFC"""
        tmp_dir = None
        try:
            job.status = "processing"
            job.progress = 10
            job.started_at = datetime.utcnow()
            db.commit()
            self._log_conversion(db, job, "–ù–∞—á–∞—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ IFC —Ñ–∞–π–ª–∞")
            self._log_conversion(db, job, "–ù–∞—á–∞—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ RVT —Ñ–∞–π–ª–∞")
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞
            export_settings_dict = None
            if export_settings_id:
                from app.models.upload import ExportSettings
                export_settings = db.query(ExportSettings).filter(ExportSettings.id == export_settings_id).first()
                if export_settings and export_settings.settings:
                    # settings —É–∂–µ JSON, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–ø—Ä—è–º—É—é
                    if isinstance(export_settings.settings, dict):
                        export_settings_dict = export_settings.settings
                    else:
                        import json
                        export_settings_dict = json.loads(export_settings.settings) if isinstance(export_settings.settings, str) else export_settings.settings
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            tmp_dir = tempfile.mkdtemp()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            job.progress = 20
            db.commit()
            self._log_conversion(db, job, "–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π IFC —Ñ–∞–π–ª")
            self._log_conversion(db, job, "–ü–æ–ª—É—á–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π RVT —Ñ–∞–π–ª")
            
            storage_path = file_upload.storage_path
            if storage_path.startswith("local://"):
                storage_path = storage_path[8:]
            
            # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            if storage_service._use_local_storage:
                local_storage_path = storage_service._local_storage_path
                rvt_file_path = os.path.join(local_storage_path, storage_path)
            else:
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ MinIO/S3
                rvt_file_path = os.path.join(tmp_dir, file_upload.original_filename)
                storage_service.download_file(storage_path, rvt_file_path)
            
            if not os.path.exists(rvt_file_path):
                raise FileNotFoundError(f"RVT —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {rvt_file_path}")
            
            # –ü—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ IFC —Ñ–∞–π–ª–∞
            ifc_filename = Path(file_upload.original_filename).with_suffix(".ifc").name
            ifc_file_path = os.path.join(tmp_dir, ifc_filename)
            
            job.progress = 30
            db.commit()
            self._log_conversion(db, job, "IFC —Ñ–∞–π–ª –≥–æ—Ç–æ–≤ –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏", metadata={"filePath": ifc_file_path})
            self._log_conversion(db, job, "RVT —Ñ–∞–π–ª –≥–æ—Ç–æ–≤ –∫ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏", metadata={"filePath": rvt_file_path})
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
            result = await asyncio.to_thread(
                self.rvt_to_ifc.convert,
                rvt_file_path=rvt_file_path,
                output_ifc_path=ifc_file_path,
                export_settings=export_settings_dict,
            )
            
            if not result.get("success"):
                raise Exception(result.get("error", "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è RVT‚ÜíIFC –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π"))
            
            if not os.path.exists(ifc_file_path):
                raise FileNotFoundError("IFC —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
            
            job.progress = 70
            db.commit()
            self._log_conversion(db, job, "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è RVT‚ÜíIFC –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –∑–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–π —Ñ–∞–π–ª")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º IFC —Ñ–∞–π–ª –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            ifc_file_size = os.path.getsize(ifc_file_path)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –∏ –≤–µ—Ä—Å–∏–∏ –∏–∑ –ø—É—Ç–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            from app.utils.storage import extract_names_from_storage_path, sanitize_filename
            project_name, version_name = extract_names_from_storage_path(file_upload.storage_path)
            
            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ ID
            if not project_name:
                project_name = f"project_{str(file_upload.project_id).replace('-', '')[:8]}"
            else:
                project_name = sanitize_filename(project_name)
            
            if not version_name:
                version_name = f"version_{str(file_upload.version_id).replace('-', '')[:8]}"
            else:
                version_name = sanitize_filename(version_name)
            
            # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –¥–ª—è IFC —Ñ–∞–π–ª–∞ –≤ –ø–∞–ø–∫–µ conversions
            conversions_dir = f"projects/{project_name}/versions/{version_name}/conversions/{str(job.id)}"
            object_name = f"{conversions_dir}/{sanitize_filename(ifc_filename)}"
            
            storage_path_result = storage_service.upload_file(
                ifc_file_path,
                object_name,
                content_type="application/octet-stream",
            )
            
            job.progress = 90
            db.commit()
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å FileUpload –¥–ª—è IFC —Ñ–∞–π–ª–∞
            ifc_file_upload = FileUpload(
                user_id=file_upload.user_id,
                project_id=file_upload.project_id,
                version_id=file_upload.version_id,
                original_filename=ifc_filename,
                file_type="IFC",
                file_size=ifc_file_size,
                mime_type="application/octet-stream",
                storage_path=storage_path_result,
                storage_bucket=storage_service.bucket or "local",
                upload_status="completed",
            )
            db.add(ifc_file_upload)
            db.commit()
            self._log_conversion(db, job, "IFC —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω", metadata={"outputFileId": str(ifc_file_upload.id)})
            db.refresh(ifc_file_upload)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∑–∞–¥–∞—á—É –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            job.status = "completed"
            job.progress = 100
            job.output_file_id = ifc_file_upload.id
            job.completed_at = datetime.utcnow()
            if job.started_at:
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±–∞ datetime –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø (naive)
                started = job.started_at
                completed = job.completed_at
                if started.tzinfo is not None:
                    started = started.replace(tzinfo=None)
                if completed.tzinfo is not None:
                    completed = completed.replace(tzinfo=None)
                job.duration_seconds = int((completed - started).total_seconds())
            db.commit()
            
        except Exception as e:
            job.status = "failed"
            job.error_message = str(e)
            job.completed_at = datetime.utcnow()
            if job.started_at:
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±–∞ datetime –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø (naive)
                started = job.started_at
                completed = job.completed_at
                if started.tzinfo is not None:
                    started = started.replace(tzinfo=None)
                if completed.tzinfo is not None:
                    completed = completed.replace(tzinfo=None)
                job.duration_seconds = int((completed - started).total_seconds())
            db.commit()
            self._log_conversion(db, job, f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ RVT‚ÜíIFC: {e}", level="ERROR")
            raise
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            if tmp_dir and os.path.exists(tmp_dir):
                shutil.rmtree(tmp_dir, ignore_errors=True)

    async def _process_csv_output(
        self,
        db: Session,
        job: ConversionJob,
        source_file_upload: FileUpload,
        csv_file_path: str,
        tmp_dir: str,
    ):
        """–û–±—â–∞—è –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ CSV: —Ä–∞–∑–±–∏–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∑–∫–∞ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ –ë–î."""
        if not os.path.exists(csv_file_path):
            raise FileNotFoundError(f"CSV —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {csv_file_path}")

        csv_filename = Path(csv_file_path).name
        csv_base_name = Path(csv_filename).stem

        csv_chunker = CSVChunkerService(max_rows_per_chunk=800000)
        chunk_files, manifest = csv_chunker.split_csv_file(
            csv_file_path=csv_file_path,
            output_dir=tmp_dir,
            base_filename=csv_base_name,
        )

        job.progress = max(job.progress or 0, 60)
        db.commit()
        self._log_conversion(
            db,
            job,
            "–†–∞–∑–±–∏–≤–∞–µ–º CSV –¥–∞–Ω–Ω—ã–µ –Ω–∞ —á–∞—Å—Ç–∏",
            metadata={"parts": len(chunk_files)},
        )

        from app.utils.storage import build_storage_path, extract_names_from_storage_path

        storage_path = source_file_upload.storage_path
        project_name, version_name = extract_names_from_storage_path(storage_path)

        csv_file_uploads: List[FileUpload] = []
        total_csv_size = 0

        for chunk_file_path in chunk_files:
            chunk_filename = os.path.basename(chunk_file_path)
            chunk_file_size = os.path.getsize(chunk_file_path)
            total_csv_size += chunk_file_size

            object_name = build_storage_path(
                project_id=source_file_upload.project_id,
                version_id=source_file_upload.version_id,
                filename=chunk_filename,
                project_name=project_name,
                version_name=version_name,
                use_original_filename=True,
            )

            storage_path_result = storage_service.upload_file(
                chunk_file_path,
                object_name,
                content_type="text/csv",
            )

            chunk_file_upload = FileUpload(
                user_id=source_file_upload.user_id,
                project_id=source_file_upload.project_id,
                version_id=source_file_upload.version_id,
                original_filename=chunk_filename,
                file_type="CSV",
                file_size=chunk_file_size,
                mime_type="text/csv",
                storage_path=storage_path_result,
                storage_bucket=storage_service.bucket or "local",
                upload_status="completed",
            )
            db.add(chunk_file_upload)
            csv_file_uploads.append(chunk_file_upload)

        if not csv_file_uploads:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏ CSV –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏")

        db.commit()
        for chunk_upload in csv_file_uploads:
            db.refresh(chunk_upload)

        self._log_conversion(
            db,
            job,
            "CSV —á–∞—Å—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ",
            metadata={"parts": len(csv_file_uploads), "totalSize": total_csv_size},
        )

        if manifest["total_parts"] > 1:
            manifest_filename = f"{csv_base_name}_manifest.json"
            manifest_path = os.path.join(tmp_dir, manifest_filename)
            import json

            with open(manifest_path, "w", encoding="utf-8") as f:
                json.dump(manifest, f, ensure_ascii=False, indent=2)

            manifest_object_name = build_storage_path(
                project_id=source_file_upload.project_id,
                version_id=source_file_upload.version_id,
                filename=manifest_filename,
                project_name=project_name,
                version_name=version_name,
                use_original_filename=True,
            )

            storage_service.upload_file(
                manifest_path,
                manifest_object_name,
                content_type="application/json",
            )
            self._log_conversion(
                db,
                job,
                "Manifest —Å–æ—Ö—Ä–∞–Ω–µ–Ω",
                metadata={"manifest": manifest_filename},
            )

        main_csv_file_upload = csv_file_uploads[0]

        job.progress = max(job.progress or 0, 85)
        db.commit()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º CSV –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
        total_rows_loaded = 0
        csv_loader = CSVLoaderService()
        for chunk_file_upload, chunk_file_path in zip(csv_file_uploads, chunk_files):
            load_result = await csv_loader.load_csv_to_db(
                db=db,
                file_upload=chunk_file_upload,
                csv_file_path=chunk_file_path,
            )
            if load_result.get("success"):
                total_rows_loaded += load_result.get("rows_loaded", 0)
            else:
                self._log_conversion(
                    db,
                    job,
                    f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ CSV —á–∞—Å—Ç–∏ {chunk_file_upload.original_filename}: {load_result.get('error')}",
                    level="ERROR",
                )

        self._log_conversion(
            db,
            job,
            "CSV –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –ë–î",
            metadata={"rows": total_rows_loaded},
        )

        # –§–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–¥–∞—á—É
        job.status = "completed"
        job.progress = 100
        job.output_file_id = main_csv_file_upload.id
        job.completed_at = datetime.utcnow()
        if job.started_at:
            started = job.started_at.replace(tzinfo=None) if job.started_at.tzinfo else job.started_at
            completed = job.completed_at.replace(tzinfo=None) if job.completed_at.tzinfo else job.completed_at
            job.duration_seconds = int((completed - started).total_seconds())
        db.commit()
        self._log_conversion(
            db,
            job,
            "CSV —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω",
            metadata={"outputFileId": str(main_csv_file_upload.id)},
        )
    
    async def _convert_ifc_to_csv(
        self,
        db: Session,
        job: ConversionJob,
        file_upload: FileUpload,
    ):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å IFC –≤ CSV"""
        tmp_dir = None
        try:
            job.status = "processing"
            job.progress = 10
            job.started_at = datetime.utcnow()
            db.commit()
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            tmp_dir = tempfile.mkdtemp()
            
            # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            job.progress = 20
            db.commit()
            
            storage_path = file_upload.storage_path
            if storage_path.startswith("local://"):
                storage_path = storage_path[8:]
            
            # –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
            if storage_service._use_local_storage:
                local_storage_path = storage_service._local_storage_path
                ifc_file_path = os.path.join(local_storage_path, storage_path)
            else:
                # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª –∏–∑ MinIO/S3
                ifc_file_path = os.path.join(tmp_dir, file_upload.original_filename)
                storage_service.download_file(storage_path, ifc_file_path)
            
            if not os.path.exists(ifc_file_path):
                raise FileNotFoundError(f"IFC —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {ifc_file_path}")
            
            # –ü—É—Ç—å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ CSV —Ñ–∞–π–ª–∞
            csv_filename = Path(file_upload.original_filename).with_suffix(".csv").name
            csv_file_path = os.path.join(tmp_dir, csv_filename)
            original_filename = file_upload.original_filename
            model_display_name = original_filename or Path(ifc_file_path).name
            
            job.progress = 30
            db.commit()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
            result = await asyncio.to_thread(
                self.ifc_to_csv.convert,
                ifc_file_path=ifc_file_path,
                output_csv_path=csv_file_path,
                model_name=model_display_name,
            )
            
            if not result.get("success"):
                raise Exception(result.get("error", "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è IFC‚ÜíCSV –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π"))
            
            if not os.path.exists(csv_file_path):
                raise FileNotFoundError("CSV —Ñ–∞–π–ª –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
            
            job.progress = 50
            db.commit()
            self._log_conversion(db, job, "–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è IFC‚ÜíCSV –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É")
            await self._process_csv_output(
                db=db,
                job=job,
                source_file_upload=file_upload,
                csv_file_path=csv_file_path,
                tmp_dir=tmp_dir,
            )
            
        except Exception as e:
            job.status = "failed"
            job.error_message = str(e)
            job.completed_at = datetime.utcnow()
            if job.started_at:
                # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –æ–±–∞ datetime –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–∏–ø (naive)
                started = job.started_at
                completed = job.completed_at
                if started.tzinfo is not None:
                    started = started.replace(tzinfo=None)
                if completed.tzinfo is not None:
                    completed = completed.replace(tzinfo=None)
                job.duration_seconds = int((completed - started).total_seconds())
            db.commit()
            self._log_conversion(db, job, f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ IFC‚ÜíCSV: {e}", level="ERROR")
            raise
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            if tmp_dir and os.path.exists(tmp_dir):
                shutil.rmtree(tmp_dir, ignore_errors=True)
    
    async def process_queue(self, db: Session) -> Optional[ConversionJob]:
        """
        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ—á–µ—Ä–µ–¥—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–π
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥–∏ (status="queued") –∏ –µ—Å—Ç—å –ª–∏ —Å–≤–æ–±–æ–¥–Ω—ã–µ —Å–ª–æ—Ç—ã –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ.
        –ï—Å–ª–∏ –æ–±–∞ —É—Å–ª–æ–≤–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞–¥–∞—á–∏ (–¥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤).
        
        Args:
            db: –°–µ—Å—Å–∏—è –ë–î
            
        Returns:
            ConversionJob –µ—Å–ª–∏ –∑–∞–¥–∞—á–∞ –±—ã–ª–∞ –∑–∞–ø—É—â–µ–Ω–∞, None –µ—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥–∏ –¥–ª—è RVT_TO_CSV
        queued_jobs = db.query(ConversionJob).filter(
            ConversionJob.status == "queued",
            ConversionJob.conversion_type == "RVT_TO_CSV",
        ).order_by(ConversionJob.id).all()  # –ë–µ—Ä–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥–∏
        
        if not queued_jobs:
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤ –Ω–∞ Windows —Å–µ—Ä–≤–µ—Ä–µ
        try:
            exporter = self.rvt_csv_exporter
            if exporter.use_remote and exporter.remote_service:
                available_slots = await exporter.remote_service.get_available_slots()
                
                if available_slots <= 0:
                    # –ù–µ—Ç —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
                    return None
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ç–æ–ª—å–∫–æ –∑–∞–¥–∞—á, —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–æ—Ç–æ–≤
                jobs_to_start = min(len(queued_jobs), available_slots)
                
                started_job = None
                for i in range(jobs_to_start):
                    queued_job = queued_jobs[i]
                    
                    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª
                    file_upload = db.query(FileUpload).filter(FileUpload.id == queued_job.file_upload_id).first()
                    if not file_upload:
                        queued_job.status = "failed"
                        queued_job.error_message = "–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"
                        db.commit()
                        continue
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏
                    queued_job.status = "processing"
                    queued_job.started_at = datetime.utcnow()
                    db.commit()
                    db.refresh(queued_job)
                    
                    self._log_conversion(
                        db,
                        queued_job,
                        "–ó–∞–¥–∞—á–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∞ –∏–∑ –æ—á–µ—Ä–µ–¥–∏, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è",
                        level="INFO",
                    )
                    
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–µ –∂–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º asyncio.create_task –¥–ª—è —Ñ–æ–Ω–æ–≤–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                        task = asyncio.create_task(
                            self._convert_rvt_to_csv(db, queued_job, file_upload, queued_job.export_settings_id)
                        )
                        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –¥–ª—è –∑–∞–¥–∞—á–∏
                        def handle_task_error(task):
                            try:
                                task.result()
                            except Exception as e:
                                print(f"‚ö†Ô∏è [ConversionService] –û—à–∏–±–∫–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ job_id={queued_job.id}: {e}")
                        
                        task.add_done_callback(handle_task_error)
                        if started_job is None:
                            started_job = queued_job
                    except Exception as e:
                        print(f"‚ö†Ô∏è [ConversionService] –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
                        queued_job.status = "failed"
                        queued_job.error_message = str(e)
                        db.commit()
                
                return started_job
            else:
                # –õ–æ–∫–∞–ª—å–Ω—ã–π –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä, –Ω–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—á–µ—Ä–µ–¥—å
                return None
        except Exception as e:
            print(f"‚ö†Ô∏è [ConversionService] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Å—Ç–∞—Ç—É—Å–∞ Windows —Å–µ—Ä–≤–µ—Ä–∞: {e}")
            return None
